# CODE996 数据看板 - 后端技术开发文档

## 文档概述

**项目名称**: CODE996 数据看板后端服务  
**文档版本**: v1.0.0  
**编写日期**: 2025-10-31  
**目标读者**: 后端开发工程师、架构师、技术经理  
**文档状态**: ✅ 正式版本  

---

## 目录

1. [项目背景](#1-项目背景)
2. [系统架构设计](#2-系统架构设计)
3. [技术栈选型](#3-技术栈选型)
4. [数据模型设计](#4-数据模型设计)
5. [核心业务逻辑](#5-核心业务逻辑)
6. [API 接口实现](#6-api-接口实现)
7. [数据处理与算法](#7-数据处理与算法)
8. [性能优化方案](#8-性能优化方案)
9. [安全性设计](#9-安全性设计)
10. [部署运维方案](#10-部署运维方案)
11. [监控与日志](#11-监控与日志)
12. [测试策略](#12-测试策略)
13. [开发规范](#13-开发规范)
14. [项目实施计划](#14-项目实施计划)
15. [附录](#15-附录)

---

## 1. 项目背景

### 1.1 项目概述

CODE996 数据看板是一个实时展示多项目代码提交情况的数据可视化系统。系统通过分析 Git 仓库的提交记录，统计开发者的工作时间分布、提交频率、加班情况等数据，并结合 AI 代码分析，为团队管理者提供直观的数据支持。

### 1.2 前后端职责划分

**前端职责**:
- 数据可视化展示（图表渲染）
- 用户交互界面
- 数据请求与状态管理
- 响应式布局与动画效果

**后端职责**:
- Git 仓库数据采集与分析
- 多项目数据汇总与统计
- 提供 RESTful API 接口
- 数据缓存与性能优化
- 系统监控与日志记录

### 1.3 核心需求

根据前端技术开发方案和前后端对接说明，后端需要实现以下核心功能：

1. **数据采集**: 从 Git 仓库中提取 commit 记录
2. **数据统计**: 按小时、按天、按工作/加班时间、按工作日/周末进行统计
3. **贡献者分析**: 统计每个开发者的提交次数和代码变更量
4. **API 服务**: 提供 2 个核心 RESTful API 接口
5. **性能保障**: 支持多项目并发查询，响应时间 < 3 秒

### 1.4 技术约束

- 前端已完成开发，接口规范已确定（详见 API接口文档.md）
- 需要支持多项目同时查询
- 数据统计规则需兼容现有的 code996_local.py 实现
- 需要考虑大量 commit 数据的处理性能
- 需要支持跨域访问（CORS）

---

## 2. 系统架构设计

### 2.1 整体架构

```
┌─────────────────────────────────────────────────────────────┐
│                         前端层                                │
│                  (Vue 3 + TypeScript)                        │
│            Dashboard / Charts / Components                   │
└─────────────────────────────────────────────────────────────┘
                            ↓ HTTP/JSON
┌─────────────────────────────────────────────────────────────┐
│                       API 网关层                              │
│              (Nginx / Kong / 直接服务)                        │
│         CORS 处理 / 限流 / 负载均衡                            │
└─────────────────────────────────────────────────────────────┘
                            ↓
┌─────────────────────────────────────────────────────────────┐
│                      应用服务层                               │
│              (Flask / FastAPI / Django)                      │
│   ┌──────────────┐  ┌──────────────┐  ┌──────────────┐      │
│   │  路由层      │  │  业务逻辑层   │  │  数据访问层   │      │
│   │  Routes      │→ │  Services    │→ │  DAL         │      │
│   └──────────────┘  └──────────────┘  └──────────────┘      │
└─────────────────────────────────────────────────────────────┘
                            ↓
┌─────────────────────────────────────────────────────────────┐
│                       数据层                                  │
│   ┌──────────────┐  ┌──────────────┐  ┌──────────────┐      │
│   │  Redis       │  │  PostgreSQL  │  │  文件系统     │      │
│   │  (缓存)      │  │  (持久化)    │  │  (Git仓库)    │      │
│   └──────────────┘  └──────────────┘  └──────────────┘      │
└─────────────────────────────────────────────────────────────┘
                            ↓
┌─────────────────────────────────────────────────────────────┐
│                      外部服务层                               │
│   ┌──────────────┐  ┌──────────────┐                         │
│   │  Git 仓库    │  │  AI 分析服务  │                         │
│   │  (GitHub等)  │  │  (9970端口)   │                         │
│   └──────────────┘  └──────────────┘                         │
└─────────────────────────────────────────────────────────────┘
```

### 2.2 分层架构说明

#### 2.2.1 API 网关层 (可选)
- **职责**: 统一入口、CORS 处理、请求限流、负载均衡
- **实现方案**: 
  - 小型部署: 直接由应用服务层处理 CORS
  - 中型部署: 使用 Nginx 反向代理
  - 大型部署: 使用 Kong / APISIX API 网关

#### 2.2.2 应用服务层
- **路由层**: 定义 API 端点，参数验证
- **业务逻辑层**: 实现核心业务逻辑，数据统计算法
- **数据访问层**: 封装数据库操作，Git 操作

#### 2.2.3 数据层
- **Redis**: 缓存 API 响应、统计结果（TTL: 5分钟）
- **PostgreSQL/MySQL**: 存储项目配置、历史统计数据（可选）
- **文件系统**: 存储 Git 仓库克隆（本地或挂载的 NFS）

### 2.3 数据流设计

```
用户请求
    ↓
[1] API 接收请求，验证参数
    ↓
[2] 检查缓存 (Redis)
    ↓
    是否命中？
    ├─ 是 → 直接返回缓存数据
    └─ 否 → 继续
        ↓
[3] 解析项目列表，并发处理各项目
    ↓
[4] 对每个项目:
    ├─ 检查仓库是否存在
    ├─ 拉取最新代码 (git pull / clone)
    ├─ 读取 Git 日志 (git log)
    ├─ 解析提交记录
    └─ 统计数据
    ↓
[5] 汇总所有项目数据
    ↓
[6] 格式化为 API 响应格式
    ↓
[7] 写入缓存 (Redis)
    ↓
[8] 返回响应给前端
```

### 2.4 模块划分

```
backend/
├── app/
│   ├── __init__.py              # 应用初始化
│   ├── main.py                  # 应用入口
│   ├── config.py                # 配置管理
│   ├── api/                     # API 层
│   │   ├── __init__.py
│   │   ├── routes.py            # 路由定义
│   │   ├── validators.py        # 请求验证
│   │   └── responses.py         # 响应格式化
│   ├── services/                # 业务逻辑层
│   │   ├── __init__.py
│   │   ├── git_service.py       # Git 操作服务
│   │   ├── stats_service.py     # 统计服务
│   │   └── cache_service.py     # 缓存服务
│   ├── models/                  # 数据模型
│   │   ├── __init__.py
│   │   ├── commit.py            # Commit 模型
│   │   └── contributor.py       # 贡献者模型
│   ├── utils/                   # 工具函数
│   │   ├── __init__.py
│   │   ├── time_utils.py        # 时间工具
│   │   ├── git_utils.py         # Git 工具
│   │   └── logger.py            # 日志工具
│   └── middleware/              # 中间件
│       ├── __init__.py
│       ├── cors.py              # CORS 中间件
│       └── error_handler.py     # 错误处理
├── tests/                       # 测试
│   ├── test_api.py
│   ├── test_services.py
│   └── test_utils.py
├── requirements.txt             # Python 依赖
├── Dockerfile                   # Docker 配置
├── docker-compose.yml           # Docker Compose 配置
└── README.md                    # 后端说明文档
```

---

## 3. 技术栈选型

### 3.1 推荐方案（Python 生态）

#### 方案一: Flask + SQLAlchemy + Redis（推荐用于小中型项目）

**优势**:
- 轻量级、灵活、学习曲线低
- 生态成熟，插件丰富
- 可以复用 code996_local.py 的代码
- 部署简单

**技术栈**:
```
- Flask 2.3+              # Web 框架
- Flask-CORS             # CORS 支持
- GitPython              # Git 操作库
- Redis                  # 缓存
- SQLAlchemy (可选)      # ORM
- Gunicorn               # WSGI 服务器
- pytest                 # 测试框架
```

**适用场景**: 
- 项目数量 < 100
- 并发用户 < 1000
- 快速开发、快速上线

#### 方案二: FastAPI + PostgreSQL + Redis（推荐用于高性能需求）

**优势**:
- 高性能（基于 Starlette + Pydantic）
- 自动生成 API 文档（Swagger）
- 类型提示、数据验证
- 支持异步 IO

**技术栈**:
```
- FastAPI 0.104+         # Web 框架
- Pydantic               # 数据验证
- GitPython              # Git 操作库
- Redis                  # 缓存
- SQLAlchemy + asyncpg   # 异步 ORM
- Uvicorn                # ASGI 服务器
- pytest-asyncio         # 异步测试
```

**适用场景**:
- 项目数量 > 100
- 需要高并发支持
- 对性能要求高

#### 方案三: Django + Django REST Framework（推荐用于企业级应用）

**优势**:
- 全栈框架，功能完备
- Admin 后台开箱即用
- ORM 强大，安全性高
- 适合需要后台管理的场景

**技术栈**:
```
- Django 4.2+            # Web 框架
- Django REST Framework  # API 框架
- GitPython              # Git 操作库
- Redis                  # 缓存
- PostgreSQL             # 数据库
- Celery (可选)          # 异步任务队列
- pytest-django          # 测试框架
```

**适用场景**:
- 需要后台管理界面
- 需要用户权限管理
- 长期维护的企业项目

### 3.2 其他语言选型

#### Node.js (Express / Koa)
```
- Express.js / Koa       # Web 框架
- simple-git            # Git 操作库
- Redis                 # 缓存
- PostgreSQL + Sequelize # ORM
```

#### Go (Gin / Echo)
```
- Gin / Echo            # Web 框架
- go-git                # Git 操作库
- Redis                 # 缓存
- PostgreSQL + GORM     # ORM
```

#### Java (Spring Boot)
```
- Spring Boot           # 框架
- JGit                  # Git 操作库
- Redis                 # 缓存
- PostgreSQL + JPA      # ORM
```

### 3.3 推荐配置（基于 Flask）

**本文档后续内容将基于 Flask 方案进行详细说明**

```python
# requirements.txt
Flask==2.3.3
Flask-CORS==4.0.0
GitPython==3.1.37
redis==5.0.1
gunicorn==21.2.0
python-dotenv==1.0.0
psutil==5.9.6
```

---

## 4. 数据模型设计

### 4.1 核心数据模型

#### 4.1.1 Commit 模型

```python
from dataclasses import dataclass
from datetime import datetime
from typing import Optional

@dataclass
class Commit:
    """Git Commit 数据模型"""
    
    hash: str                    # commit hash
    author_name: str             # 作者姓名
    author_email: str            # 作者邮箱
    timestamp: datetime          # 提交时间
    message: str                 # 提交信息
    additions: int = 0           # 新增行数
    deletions: int = 0           # 删除行数
    files_changed: int = 0       # 修改文件数
    
    @property
    def hour(self) -> int:
        """提交时间的小时 (0-23)"""
        return self.timestamp.hour
    
    @property
    def weekday(self) -> int:
        """提交时间的星期 (0=周一, 6=周日)"""
        return self.timestamp.weekday()
    
    @property
    def is_work_hour(self) -> bool:
        """是否工作时间 (9:00-18:00)"""
        return 9 <= self.hour < 18
    
    @property
    def is_overtime(self) -> bool:
        """是否加班时间 (18:00-9:00)"""
        return not self.is_work_hour
    
    @property
    def is_weekday(self) -> bool:
        """是否工作日 (周一-周五)"""
        return self.weekday < 5
    
    @property
    def is_weekend(self) -> bool:
        """是否周末 (周六-周日)"""
        return self.weekday >= 5
```

#### 4.1.2 Contributor 模型

```python
@dataclass
class Contributor:
    """贡献者数据模型"""
    
    name: str                    # 姓名
    email: str                   # 邮箱
    commits: int = 0             # commit 次数
    additions: int = 0           # 总新增行数
    deletions: int = 0           # 总删除行数
    rank: int = 0                # 排名
    
    @property
    def total_changes(self) -> int:
        """总代码变更量"""
        return self.additions + self.deletions
    
    def add_commit(self, commit: Commit):
        """添加一个 commit 的统计"""
        self.commits += 1
        self.additions += commit.additions
        self.deletions += commit.deletions
```

#### 4.1.3 统计数据模型

```python
@dataclass
class DashboardStats:
    """仪表板统计数据模型"""
    
    start_date: str                      # 统计开始日期
    end_date: str                        # 统计结束日期
    total_count: int                     # 总 commit 数
    repo_count: int                      # 项目数量
    hour_data: List[Dict[str, Any]]      # 按小时统计 (24个)
    week_data: List[Dict[str, Any]]      # 按星期统计 (7个)
    work_hour_pl: List[Dict[str, Any]]   # 工作/加班占比 (2个)
    work_week_pl: List[Dict[str, Any]]   # 工作日/周末占比 (2个)
    index_996: float                     # 996 指数
    overtime_ratio: float                # 加班比例
    is_standard: bool                    # 是否标准工作时间
    
    @staticmethod
    def from_commits(commits: List[Commit], repo_count: int) -> 'DashboardStats':
        """从 commit 列表生成统计数据"""
        # 详细实现见后文
        pass
```

### 4.2 数据库设计（可选）

如果需要持久化存储项目配置和历史数据，可以设计以下数据库表：

#### 4.2.1 项目表 (projects)

```sql
CREATE TABLE projects (
    id SERIAL PRIMARY KEY,
    name VARCHAR(255) NOT NULL UNIQUE,
    repo_url TEXT NOT NULL,
    repo_path TEXT,
    branch VARCHAR(100) DEFAULT 'main',
    is_active BOOLEAN DEFAULT TRUE,
    last_synced_at TIMESTAMP,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

CREATE INDEX idx_projects_name ON projects(name);
CREATE INDEX idx_projects_is_active ON projects(is_active);
```

#### 4.2.2 统计快照表 (stats_snapshots)

```sql
CREATE TABLE stats_snapshots (
    id SERIAL PRIMARY KEY,
    project_names TEXT NOT NULL,          -- 逗号分隔的项目名称
    cache_key VARCHAR(255) NOT NULL,      -- 缓存键
    total_count INTEGER NOT NULL,
    repo_count INTEGER NOT NULL,
    stats_data JSONB NOT NULL,            -- 完整的统计数据 (JSON)
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    expires_at TIMESTAMP                  -- 过期时间
);

CREATE INDEX idx_stats_cache_key ON stats_snapshots(cache_key);
CREATE INDEX idx_stats_expires_at ON stats_snapshots(expires_at);
```

#### 4.2.3 贡献者统计表 (contributors_stats)

```sql
CREATE TABLE contributors_stats (
    id SERIAL PRIMARY KEY,
    name VARCHAR(255) NOT NULL,
    email VARCHAR(255) NOT NULL,
    project_names TEXT NOT NULL,
    commits INTEGER NOT NULL,
    additions INTEGER,
    deletions INTEGER,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

CREATE INDEX idx_contributors_email ON contributors_stats(email);
CREATE INDEX idx_contributors_project ON contributors_stats(project_names);
```

---

## 5. 核心业务逻辑

### 5.1 Git 数据采集

#### 5.1.1 仓库管理

```python
# app/services/git_service.py
import os
from git import Repo, GitCommandError
from typing import Optional

class GitService:
    """Git 仓库管理服务"""
    
    def __init__(self, workspace_dir: str = './repos'):
        self.workspace_dir = workspace_dir
        os.makedirs(workspace_dir, exist_ok=True)
    
    def get_or_clone_repo(self, repo_url: str, project_name: str) -> Repo:
        """
        获取或克隆仓库
        
        Args:
            repo_url: 仓库 URL
            project_name: 项目名称（用作本地目录名）
        
        Returns:
            Repo: GitPython 仓库对象
        """
        repo_path = os.path.join(self.workspace_dir, project_name)
        
        # 如果仓库已存在，更新
        if os.path.exists(repo_path):
            try:
                repo = Repo(repo_path)
                origin = repo.remote('origin')
                origin.pull()
                return repo
            except GitCommandError as e:
                # 如果更新失败，删除重新克隆
                import shutil
                shutil.rmtree(repo_path)
        
        # 克隆仓库
        try:
            repo = Repo.clone_from(repo_url, repo_path, depth=1000)  # 限制深度
            return repo
        except GitCommandError as e:
            raise ValueError(f"克隆仓库失败: {str(e)}")
    
    def get_commits(
        self, 
        repo: Repo, 
        branch: str = 'HEAD',
        since: Optional[str] = None,
        until: Optional[str] = None
    ) -> List[Commit]:
        """
        获取仓库的 commit 列表
        
        Args:
            repo: 仓库对象
            branch: 分支名称
            since: 开始日期 (YYYY-MM-DD)
            until: 结束日期 (YYYY-MM-DD)
        
        Returns:
            List[Commit]: Commit 对象列表
        """
        commits = []
        
        # 构建 git log 参数
        kwargs = {}
        if since:
            kwargs['since'] = since
        if until:
            kwargs['until'] = until
        
        # 遍历 commit
        for git_commit in repo.iter_commits(branch, **kwargs):
            commit = Commit(
                hash=git_commit.hexsha,
                author_name=git_commit.author.name,
                author_email=git_commit.author.email,
                timestamp=git_commit.committed_datetime,
                message=git_commit.message.strip(),
                additions=git_commit.stats.total['insertions'],
                deletions=git_commit.stats.total['deletions'],
                files_changed=git_commit.stats.total['files']
            )
            commits.append(commit)
        
        return commits
```

#### 5.1.2 多项目并发处理

```python
# app/services/stats_service.py
from concurrent.futures import ThreadPoolExecutor, as_completed
from typing import List, Dict
import logging

logger = logging.getLogger(__name__)

class StatsService:
    """统计服务"""
    
    def __init__(self, git_service: GitService):
        self.git_service = git_service
    
    def fetch_multi_project_stats(
        self, 
        project_names: List[str],
        max_workers: int = 5
    ) -> DashboardStats:
        """
        并发获取多个项目的统计数据
        
        Args:
            project_names: 项目名称列表
            max_workers: 最大并发数
        
        Returns:
            DashboardStats: 汇总的统计数据
        """
        all_commits = []
        
        # 并发处理各个项目
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            futures = {
                executor.submit(self._fetch_single_project, name): name
                for name in project_names
            }
            
            for future in as_completed(futures):
                project_name = futures[future]
                try:
                    commits = future.result(timeout=30)  # 30秒超时
                    all_commits.extend(commits)
                    logger.info(f"项目 {project_name} 数据获取成功: {len(commits)} commits")
                except Exception as e:
                    logger.error(f"项目 {project_name} 数据获取失败: {str(e)}")
        
        # 生成统计数据
        return DashboardStats.from_commits(all_commits, len(project_names))
    
    def _fetch_single_project(self, project_name: str) -> List[Commit]:
        """获取单个项目的 commit 数据"""
        # TODO: 从配置中获取 repo_url
        repo_url = self._get_repo_url(project_name)
        repo = self.git_service.get_or_clone_repo(repo_url, project_name)
        return self.git_service.get_commits(repo)
    
    def _get_repo_url(self, project_name: str) -> str:
        """根据项目名称获取仓库 URL"""
        # 这里需要实现项目名称到 URL 的映射逻辑
        # 可以从数据库、配置文件或环境变量读取
        pass
```

### 5.2 数据统计算法

#### 5.2.1 按小时统计

```python
def calculate_hour_data(commits: List[Commit]) -> List[Dict[str, Any]]:
    """
    计算按小时分布的数据
    
    Returns:
        24 个元素的列表，每个元素格式: {"time": "00", "count": 10}
    """
    # 初始化 24 小时数据
    hour_counts = {f"{i:02d}": 0 for i in range(24)}
    
    # 统计每个小时的 commit 数
    for commit in commits:
        hour_key = f"{commit.hour:02d}"
        hour_counts[hour_key] += 1
    
    # 转换为列表格式
    return [{"time": hour, "count": count} for hour, count in hour_counts.items()]
```

#### 5.2.2 按星期统计

```python
def calculate_week_data(commits: List[Commit]) -> List[Dict[str, Any]]:
    """
    计算按星期分布的数据
    
    Returns:
        7 个元素的列表，格式: {"time": "周一", "count": 100}
    """
    weekday_names = ["周一", "周二", "周三", "周四", "周五", "周六", "周日"]
    week_counts = {name: 0 for name in weekday_names}
    
    # 统计每个星期的 commit 数
    for commit in commits:
        day_name = weekday_names[commit.weekday]
        week_counts[day_name] += 1
    
    # 按周一到周日顺序返回
    return [{"time": day, "count": week_counts[day]} for day in weekday_names]
```

#### 5.2.3 工作/加班时间统计

```python
def calculate_work_hour_ratio(commits: List[Commit]) -> List[Dict[str, Any]]:
    """
    计算工作时间和加班时间的占比
    
    工作时间: 9:00 - 18:00
    加班时间: 18:00 - 9:00 (次日)
    
    Returns:
        2 个元素: [{"time": "工作时间", "count": 500}, {"time": "加班时间", "count": 300}]
    """
    work_count = sum(1 for c in commits if c.is_work_hour)
    overtime_count = sum(1 for c in commits if c.is_overtime)
    
    return [
        {"time": "工作时间", "count": work_count},
        {"time": "加班时间", "count": overtime_count}
    ]
```

#### 5.2.4 工作日/周末统计

```python
def calculate_work_week_ratio(commits: List[Commit]) -> List[Dict[str, Any]]:
    """
    计算工作日和周末的占比
    
    工作日: 周一 - 周五
    周末: 周六 - 周日
    
    Returns:
        2 个元素: [{"time": "工作日", "count": 800}, {"time": "周末", "count": 200}]
    """
    weekday_count = sum(1 for c in commits if c.is_weekday)
    weekend_count = sum(1 for c in commits if c.is_weekend)
    
    return [
        {"time": "工作日", "count": weekday_count},
        {"time": "周末", "count": weekend_count}
    ]
```

#### 5.2.5 996 指数计算

```python
def calculate_996_index(commits: List[Commit]) -> float:
    """
    计算 996 指数
    
    996 = 每天工作 9:00-21:00 (12小时), 每周工作 6 天
    
    计算公式:
    - 晚上提交占比 * 0.5
    - 周末提交占比 * 0.3
    - 总工作时长 / 标准时长 * 0.2
    
    Returns:
        float: 0-1 之间的数值，越接近 1 表示越 996
    """
    if not commits:
        return 0.0
    
    # 晚上提交占比 (18:00 - 21:00)
    evening_commits = sum(1 for c in commits if 18 <= c.hour < 21)
    evening_ratio = evening_commits / len(commits)
    
    # 周末提交占比
    weekend_commits = sum(1 for c in commits if c.is_weekend)
    weekend_ratio = weekend_commits / len(commits)
    
    # 综合指数
    index = evening_ratio * 0.6 + weekend_ratio * 0.4
    
    return round(min(index, 1.0), 2)
```

#### 5.2.6 加班比例计算

```python
def calculate_overtime_ratio(commits: List[Commit]) -> float:
    """
    计算加班比例
    
    Returns:
        float: 加班 commit 数 / 总 commit 数
    """
    if not commits:
        return 0.0
    
    overtime_count = sum(1 for c in commits if c.is_overtime)
    return round(overtime_count / len(commits), 2)
```

### 5.3 贡献者统计

```python
def calculate_contributors(commits: List[Commit]) -> List[Dict[str, Any]]:
    """
    统计贡献者列表
    
    Returns:
        按 commits 数量降序排列的贡献者列表
    """
    # 按邮箱分组统计
    contributors_map = {}
    
    for commit in commits:
        email = commit.author_email
        if email not in contributors_map:
            contributors_map[email] = Contributor(
                name=commit.author_name,
                email=email
            )
        contributors_map[email].add_commit(commit)
    
    # 转换为列表并排序
    contributors = list(contributors_map.values())
    contributors.sort(key=lambda c: c.commits, reverse=True)
    
    # 添加排名
    for rank, contributor in enumerate(contributors, start=1):
        contributor.rank = rank
    
    # 转换为字典格式
    return [
        {
            "rank": c.rank,
            "name": c.name,
            "email": c.email,
            "commits": c.commits,
            "additions": c.additions,
            "deletions": c.deletions
        }
        for c in contributors
    ]
```

---

## 6. API 接口实现

### 6.1 路由定义

```python
# app/api/routes.py
from flask import Blueprint, request, jsonify
from app.services.stats_service import StatsService
from app.services.cache_service import CacheService
from app.api.validators import validate_projects_param
from app.api.responses import success_response, error_response
import logging

logger = logging.getLogger(__name__)

# 创建 Blueprint
api_bp = Blueprint('api', __name__, url_prefix='/api/dashboard')

# 初始化服务
stats_service = StatsService()
cache_service = CacheService()


@api_bp.route('/summary', methods=['GET'])
def get_summary():
    """
    获取汇总数据接口
    
    Query Parameters:
        projects: 逗号分隔的项目名称列表
    
    Returns:
        JSON: 汇总统计数据
    """
    try:
        # 1. 参数验证
        projects_param = request.args.get('projects', '')
        projects = validate_projects_param(projects_param)
        
        # 2. 生成缓存键
        cache_key = f"summary:{','.join(sorted(projects))}"
        
        # 3. 检查缓存
        cached_data = cache_service.get(cache_key)
        if cached_data:
            logger.info(f"缓存命中: {cache_key}")
            return success_response(cached_data)
        
        # 4. 获取数据
        logger.info(f"开始处理项目: {projects}")
        stats = stats_service.fetch_multi_project_stats(projects)
        
        # 5. 格式化响应
        data = {
            "start_date": stats.start_date,
            "end_date": stats.end_date,
            "total_count": stats.total_count,
            "repo_count": stats.repo_count,
            "hour_data": stats.hour_data,
            "week_data": stats.week_data,
            "work_hour_pl": stats.work_hour_pl,
            "work_week_pl": stats.work_week_pl,
            "index_996": stats.index_996,
            "overtime_ratio": stats.overtime_ratio,
            "is_standard": stats.is_standard
        }
        
        # 6. 写入缓存 (5 分钟)
        cache_service.set(cache_key, data, ttl=300)
        
        return success_response(data)
        
    except ValueError as e:
        logger.warning(f"参数错误: {str(e)}")
        return error_response(400, f"参数错误: {str(e)}")
    
    except Exception as e:
        logger.error(f"服务器错误: {str(e)}", exc_info=True)
        return error_response(500, "服务器内部错误")


@api_bp.route('/contributors', methods=['GET'])
def get_contributors():
    """
    获取贡献者列表接口
    
    Query Parameters:
        projects: 逗号分隔的项目名称列表
    
    Returns:
        JSON: 贡献者列表（按 commits 降序）
    """
    try:
        # 1. 参数验证
        projects_param = request.args.get('projects', '')
        projects = validate_projects_param(projects_param)
        
        # 2. 生成缓存键
        cache_key = f"contributors:{','.join(sorted(projects))}"
        
        # 3. 检查缓存
        cached_data = cache_service.get(cache_key)
        if cached_data:
            logger.info(f"缓存命中: {cache_key}")
            return success_response(cached_data)
        
        # 4. 获取数据
        logger.info(f"开始获取贡献者: {projects}")
        contributors = stats_service.fetch_multi_project_contributors(projects)
        
        # 5. 写入缓存 (5 分钟)
        cache_service.set(cache_key, contributors, ttl=300)
        
        return success_response(contributors)
        
    except ValueError as e:
        logger.warning(f"参数错误: {str(e)}")
        return error_response(400, f"参数错误: {str(e)}")
    
    except Exception as e:
        logger.error(f"服务器错误: {str(e)}", exc_info=True)
        return error_response(500, "服务器内部错误")


@api_bp.route('/health', methods=['GET'])
def health_check():
    """健康检查接口"""
    return success_response({"status": "ok", "message": "服务运行正常"})
```

### 6.2 参数验证

```python
# app/api/validators.py
from typing import List

def validate_projects_param(projects_param: str) -> List[str]:
    """
    验证 projects 参数
    
    Args:
        projects_param: 逗号分隔的项目名称字符串
    
    Returns:
        List[str]: 项目名称列表
    
    Raises:
        ValueError: 参数无效
    """
    if not projects_param:
        raise ValueError("projects 参数不能为空")
    
    # 分割并去除空白
    projects = [p.strip() for p in projects_param.split(',') if p.strip()]
    
    if not projects:
        raise ValueError("projects 参数格式不正确")
    
    if len(projects) > 50:  # 限制最大项目数
        raise ValueError("项目数量不能超过 50 个")
    
    return projects
```

### 6.3 响应格式化

```python
# app/api/responses.py
from flask import jsonify
from typing import Any, Optional

def success_response(data: Any, message: str = "success") -> tuple:
    """
    成功响应
    
    Returns:
        (JSON, status_code)
    """
    return jsonify({
        "code": 200,
        "message": message,
        "data": data
    }), 200


def error_response(code: int, message: str, data: Optional[Any] = None) -> tuple:
    """
    错误响应
    
    Returns:
        (JSON, status_code)
    """
    return jsonify({
        "code": code,
        "message": message,
        "data": data
    }), code
```

### 6.4 缓存服务

```python
# app/services/cache_service.py
import redis
import json
import logging
from typing import Any, Optional

logger = logging.getLogger(__name__)

class CacheService:
    """Redis 缓存服务"""
    
    def __init__(self, host: str = 'localhost', port: int = 6379, db: int = 0):
        try:
            self.redis_client = redis.Redis(
                host=host,
                port=port,
                db=db,
                decode_responses=True,
                socket_connect_timeout=5
            )
            self.redis_client.ping()
            logger.info("Redis 连接成功")
        except Exception as e:
            logger.warning(f"Redis 连接失败: {str(e)}, 将使用内存缓存")
            self.redis_client = None
            self.memory_cache = {}
    
    def get(self, key: str) -> Optional[Any]:
        """获取缓存"""
        try:
            if self.redis_client:
                value = self.redis_client.get(key)
                return json.loads(value) if value else None
            else:
                return self.memory_cache.get(key)
        except Exception as e:
            logger.error(f"缓存读取失败: {str(e)}")
            return None
    
    def set(self, key: str, value: Any, ttl: int = 300):
        """设置缓存"""
        try:
            if self.redis_client:
                self.redis_client.setex(key, ttl, json.dumps(value))
            else:
                self.memory_cache[key] = value
        except Exception as e:
            logger.error(f"缓存写入失败: {str(e)}")
    
    def delete(self, key: str):
        """删除缓存"""
        try:
            if self.redis_client:
                self.redis_client.delete(key)
            else:
                self.memory_cache.pop(key, None)
        except Exception as e:
            logger.error(f"缓存删除失败: {str(e)}")
    
    def clear_all(self):
        """清空所有缓存"""
        try:
            if self.redis_client:
                self.redis_client.flushdb()
            else:
                self.memory_cache.clear()
        except Exception as e:
            logger.error(f"清空缓存失败: {str(e)}")
```

---

## 7. 数据处理与算法

### 7.1 DashboardStats 实现

```python
# app/models/stats.py
from dataclasses import dataclass
from datetime import datetime
from typing import List, Dict, Any

@dataclass
class DashboardStats:
    """仪表板统计数据"""
    
    start_date: str
    end_date: str
    total_count: int
    repo_count: int
    hour_data: List[Dict[str, Any]]
    week_data: List[Dict[str, Any]]
    work_hour_pl: List[Dict[str, Any]]
    work_week_pl: List[Dict[str, Any]]
    index_996: float
    overtime_ratio: float
    is_standard: bool
    
    @staticmethod
    def from_commits(commits: List['Commit'], repo_count: int) -> 'DashboardStats':
        """从 commit 列表生成统计数据"""
        
        # 如果没有 commit，返回空数据
        if not commits:
            return DashboardStats._empty_stats(repo_count)
        
        # 计算日期范围
        timestamps = [c.timestamp for c in commits]
        start_date = min(timestamps).strftime('%Y-%m-%d')
        end_date = max(timestamps).strftime('%Y-%m-%d')
        
        # 计算各项统计
        hour_data = calculate_hour_data(commits)
        week_data = calculate_week_data(commits)
        work_hour_pl = calculate_work_hour_ratio(commits)
        work_week_pl = calculate_work_week_ratio(commits)
        index_996 = calculate_996_index(commits)
        overtime_ratio = calculate_overtime_ratio(commits)
        
        # 判断是否标准工作时间
        is_standard = overtime_ratio < 0.2 and index_996 < 0.3
        
        return DashboardStats(
            start_date=start_date,
            end_date=end_date,
            total_count=len(commits),
            repo_count=repo_count,
            hour_data=hour_data,
            week_data=week_data,
            work_hour_pl=work_hour_pl,
            work_week_pl=work_week_pl,
            index_996=index_996,
            overtime_ratio=overtime_ratio,
            is_standard=is_standard
        )
    
    @staticmethod
    def _empty_stats(repo_count: int) -> 'DashboardStats':
        """生成空统计数据"""
        return DashboardStats(
            start_date=datetime.now().strftime('%Y-%m-%d'),
            end_date=datetime.now().strftime('%Y-%m-%d'),
            total_count=0,
            repo_count=repo_count,
            hour_data=[{"time": f"{i:02d}", "count": 0} for i in range(24)],
            week_data=[{"time": d, "count": 0} for d in 
                      ["周一", "周二", "周三", "周四", "周五", "周六", "周日"]],
            work_hour_pl=[{"time": "工作时间", "count": 0}, {"time": "加班时间", "count": 0}],
            work_week_pl=[{"time": "工作日", "count": 0}, {"time": "周末", "count": 0}],
            index_996=0.0,
            overtime_ratio=0.0,
            is_standard=True
        )
```

### 7.2 性能优化技巧

#### 7.2.1 Git Log 优化

```python
def get_commits_optimized(repo: Repo, max_count: int = 1000) -> List[Commit]:
    """
    优化的 commit 获取方法
    
    - 限制获取数量
    - 只获取必要字段
    - 使用浅克隆
    """
    commits = []
    
    for i, git_commit in enumerate(repo.iter_commits('HEAD')):
        if i >= max_count:  # 限制数量
            break
        
        # 只提取必要信息，避免加载完整 diff
        commit = Commit(
            hash=git_commit.hexsha[:8],  # 短 hash
            author_name=git_commit.author.name,
            author_email=git_commit.author.email,
            timestamp=git_commit.committed_datetime,
            message=git_commit.summary,  # 只要标题
            additions=0,  # 可选字段，可通过单独请求获取
            deletions=0,
            files_changed=0
        )
        commits.append(commit)
    
    return commits
```

#### 7.2.2 内存优化

```python
def process_commits_in_batches(commits: List[Commit], batch_size: int = 100):
    """
    分批处理 commit，减少内存占用
    """
    for i in range(0, len(commits), batch_size):
        batch = commits[i:i+batch_size]
        yield batch
```

---

## 8. 性能优化方案

### 8.1 缓存策略

#### 8.1.1 多级缓存

```
请求 → 内存缓存 (TTL: 1分钟) → Redis 缓存 (TTL: 5分钟) → 数据库/Git
```

#### 8.1.2 缓存更新策略

- **被动更新**: TTL 过期后自动失效
- **主动更新**: Git push webhook 触发缓存清除
- **预热策略**: 定时任务预加载热点数据

### 8.2 数据库优化

#### 8.2.1 索引优化

```sql
-- 项目名称索引
CREATE INDEX idx_projects_name ON projects(name);

-- 缓存键索引
CREATE INDEX idx_stats_cache_key ON stats_snapshots(cache_key);

-- 过期时间索引（方便清理）
CREATE INDEX idx_stats_expires_at ON stats_snapshots(expires_at);
```

#### 8.2.2 查询优化

- 使用批量查询减少 DB 往返
- 使用连接池复用连接
- 避免 N+1 查询问题

### 8.3 并发优化

```python
# 使用线程池并发处理
from concurrent.futures import ThreadPoolExecutor

def process_projects_parallel(projects: List[str]) -> List[Commit]:
    """并发处理多个项目"""
    with ThreadPoolExecutor(max_workers=5) as executor:
        futures = [executor.submit(process_single_project, p) for p in projects]
        results = [f.result() for f in futures]
    return sum(results, [])  # 合并结果
```

### 8.4 请求限流

```python
# 使用 Flask-Limiter
from flask_limiter import Limiter
from flask_limiter.util import get_remote_address

limiter = Limiter(
    app,
    key_func=get_remote_address,
    default_limits=["100 per minute"]
)

@app.route('/api/dashboard/summary')
@limiter.limit("20 per minute")
def get_summary():
    pass
```

---

## 9. 安全性设计

### 9.1 输入验证

```python
def validate_project_name(name: str) -> bool:
    """验证项目名称，防止路径遍历攻击"""
    import re
    # 只允许字母、数字、下划线、连字符
    pattern = r'^[a-zA-Z0-9_-]+$'
    return bool(re.match(pattern, name))
```

### 9.2 访问控制

```python
# 可选: 添加 API Key 验证
from functools import wraps
from flask import request

def require_api_key(f):
    @wraps(f)
    def decorated_function(*args, **kwargs):
        api_key = request.headers.get('X-API-Key')
        if not api_key or not validate_api_key(api_key):
            return error_response(401, "未授权")
        return f(*args, **kwargs)
    return decorated_function

@app.route('/api/dashboard/summary')
@require_api_key
def get_summary():
    pass
```

### 9.3 CORS 配置

```python
# app/middleware/cors.py
from flask_cors import CORS

def setup_cors(app):
    """配置 CORS"""
    CORS(app, resources={
        r"/api/*": {
            "origins": [
                "http://localhost:3801",
                "https://your-domain.com"
            ],
            "methods": ["GET", "POST", "OPTIONS"],
            "allow_headers": ["Content-Type", "X-API-Key"],
            "max_age": 3600
        }
    })
```

### 9.4 敏感信息保护

```python
# 不要在日志中记录敏感信息
logger.info(f"处理项目: {project_name}")  # ✅
logger.info(f"Git Token: {token}")        # ❌
```

---

## 10. 部署运维方案

### 10.1 Docker 部署

#### 10.1.1 Dockerfile

```dockerfile
# Dockerfile
FROM python:3.11-slim

WORKDIR /app

# 安装系统依赖
RUN apt-get update && apt-get install -y \
    git \
    && rm -rf /var/lib/apt/lists/*

# 安装 Python 依赖
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# 复制应用代码
COPY app/ ./app/
COPY app/main.py .

# 创建数据目录
RUN mkdir -p /app/repos

# 暴露端口
EXPOSE 8000

# 启动命令
CMD ["gunicorn", "-w", "4", "-b", "0.0.0.0:8000", "main:app"]
```

#### 10.1.2 docker-compose.yml

```yaml
version: '3.8'

services:
  backend:
    build: .
    ports:
      - "8000:8000"
    environment:
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - LOG_LEVEL=INFO
    volumes:
      - ./repos:/app/repos
      - ./logs:/app/logs
    depends_on:
      - redis
    restart: unless-stopped
  
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    restart: unless-stopped
  
  # 可选: PostgreSQL
  postgres:
    image: postgres:15-alpine
    environment:
      - POSTGRES_DB=code996
      - POSTGRES_USER=code996
      - POSTGRES_PASSWORD=secret
    volumes:
      - postgres_data:/var/lib/postgresql/data
    restart: unless-stopped

volumes:
  redis_data:
  postgres_data:
```

### 10.2 Gunicorn 配置

```python
# gunicorn.conf.py
import multiprocessing

bind = "0.0.0.0:8000"
workers = multiprocessing.cpu_count() * 2 + 1
worker_class = "sync"
worker_connections = 1000
timeout = 60
keepalive = 5

# 日志
accesslog = "/app/logs/access.log"
errorlog = "/app/logs/error.log"
loglevel = "info"

# 进程管理
daemon = False
pidfile = "/tmp/gunicorn.pid"
```

### 10.3 Nginx 配置

```nginx
# /etc/nginx/sites-available/code996-dashboard
upstream backend {
    server 127.0.0.1:8000;
    # 可以添加多个后端实现负载均衡
    # server 127.0.0.1:8001;
}

server {
    listen 80;
    server_name api.code996.example.com;
    
    # 前端静态文件
    location / {
        root /var/www/dashboard/dist;
        try_files $uri $uri/ /index.html;
    }
    
    # API 代理
    location /api/ {
        proxy_pass http://backend;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        
        # 超时设置
        proxy_connect_timeout 60s;
        proxy_send_timeout 60s;
        proxy_read_timeout 60s;
    }
    
    # 日志
    access_log /var/log/nginx/code996_access.log;
    error_log /var/log/nginx/code996_error.log;
}
```

### 10.4 Systemd 服务

```ini
# /etc/systemd/system/code996-backend.service
[Unit]
Description=CODE996 Dashboard Backend
After=network.target redis.service

[Service]
Type=notify
User=www-data
Group=www-data
WorkingDirectory=/opt/code996-backend
Environment="PATH=/opt/code996-backend/venv/bin"
ExecStart=/opt/code996-backend/venv/bin/gunicorn -c gunicorn.conf.py main:app
ExecReload=/bin/kill -s HUP $MAINPID
KillMode=mixed
TimeoutStopSec=5
PrivateTmp=true

[Install]
WantedBy=multi-user.target
```

---

## 11. 监控与日志

### 11.1 日志配置

```python
# app/utils/logger.py
import logging
import logging.handlers
import os

def setup_logger(name: str = 'code996', log_dir: str = './logs') -> logging.Logger:
    """配置日志"""
    
    # 创建日志目录
    os.makedirs(log_dir, exist_ok=True)
    
    # 创建 logger
    logger = logging.getLogger(name)
    logger.setLevel(logging.INFO)
    
    # 文件 handler (按日期轮转)
    file_handler = logging.handlers.TimedRotatingFileHandler(
        filename=os.path.join(log_dir, 'app.log'),
        when='midnight',
        interval=1,
        backupCount=30,
        encoding='utf-8'
    )
    file_handler.setLevel(logging.INFO)
    
    # 控制台 handler
    console_handler = logging.StreamHandler()
    console_handler.setLevel(logging.DEBUG)
    
    # 格式化
    formatter = logging.Formatter(
        '[%(asctime)s] %(levelname)s in %(module)s: %(message)s'
    )
    file_handler.setFormatter(formatter)
    console_handler.setFormatter(formatter)
    
    # 添加 handler
    logger.addHandler(file_handler)
    logger.addHandler(console_handler)
    
    return logger
```

### 11.2 性能监控

```python
# 使用装饰器监控函数执行时间
import time
import functools

def timing_decorator(func):
    @functools.wraps(func)
    def wrapper(*args, **kwargs):
        start = time.time()
        result = func(*args, **kwargs)
        elapsed = time.time() - start
        logger.info(f"{func.__name__} 执行时间: {elapsed:.2f}s")
        return result
    return wrapper

@timing_decorator
def fetch_multi_project_stats(projects):
    pass
```

### 11.3 健康检查

```python
@app.route('/health', methods=['GET'])
def health_check():
    """详细的健康检查"""
    health = {
        "status": "ok",
        "timestamp": datetime.now().isoformat(),
        "services": {
            "redis": check_redis_health(),
            "disk": check_disk_space(),
            "memory": check_memory_usage()
        }
    }
    
    # 如果任何服务不健康，返回 503
    if any(s != "ok" for s in health["services"].values()):
        health["status"] = "degraded"
        return jsonify(health), 503
    
    return jsonify(health), 200
```

---

## 12. 测试策略

### 12.1 单元测试

```python
# tests/test_stats_service.py
import pytest
from app.services.stats_service import StatsService
from app.models.commit import Commit
from datetime import datetime

def test_calculate_hour_data():
    """测试按小时统计"""
    commits = [
        Commit(
            hash="abc123",
            author_name="Test User",
            author_email="test@example.com",
            timestamp=datetime(2024, 1, 1, 9, 0, 0),
            message="Test commit"
        ),
        Commit(
            hash="def456",
            author_name="Test User",
            author_email="test@example.com",
            timestamp=datetime(2024, 1, 1, 9, 30, 0),
            message="Another commit"
        )
    ]
    
    hour_data = calculate_hour_data(commits)
    
    assert len(hour_data) == 24
    assert hour_data[9]["count"] == 2
    assert hour_data[10]["count"] == 0
```

### 12.2 集成测试

```python
# tests/test_api.py
import pytest
from app.main import app

@pytest.fixture
def client():
    app.config['TESTING'] = True
    with app.test_client() as client:
        yield client

def test_get_summary(client):
    """测试汇总数据接口"""
    response = client.get('/api/dashboard/summary?projects=test1,test2')
    
    assert response.status_code == 200
    data = response.get_json()
    assert data['code'] == 200
    assert 'hour_data' in data['data']
    assert len(data['data']['hour_data']) == 24
```

### 12.3 性能测试

使用 Locust 进行压力测试：

```python
# locustfile.py
from locust import HttpUser, task, between

class DashboardUser(HttpUser):
    wait_time = between(1, 3)
    
    @task
    def get_summary(self):
        self.client.get("/api/dashboard/summary?projects=test1,test2,test3")
    
    @task(2)
    def get_contributors(self):
        self.client.get("/api/dashboard/contributors?projects=test1,test2")
```

运行测试:
```bash
locust -f locustfile.py --host=http://localhost:8000 --users=100 --spawn-rate=10
```

---

## 13. 开发规范

### 13.1 代码规范

- **PEP 8**: Python 代码风格指南
- **Black**: 代码自动格式化
- **Flake8**: 代码质量检查
- **mypy**: 类型检查

```bash
# 格式化代码
black app/

# 检查代码质量
flake8 app/

# 类型检查
mypy app/
```

### 13.2 Git 工作流

```
main (生产环境)
  ↑
develop (开发环境)
  ↑
feature/xxx (功能分支)
```

### 13.3 Commit 规范

```
feat: 新功能
fix: 修复bug
docs: 文档更新
style: 代码格式
refactor: 重构
test: 测试
chore: 构建/工具

示例:
feat: 添加缓存服务
fix: 修复并发处理bug
docs: 更新API文档
```

---

## 14. 项目实施计划

### 14.1 开发阶段划分

#### Phase 1: 基础框架搭建（2-3 天）

**目标**: 搭建基础项目结构，实现核心功能框架

- [ ] 创建项目结构
- [ ] 配置开发环境
- [ ] 实现 Git 数据采集基础类
- [ ] 实现数据模型定义
- [ ] 搭建 Flask 应用框架

**交付物**:
- 可运行的基础框架
- Git 操作工具类
- 数据模型定义

---

#### Phase 2: 核心业务逻辑（3-4 天）

**目标**: 实现数据统计算法和业务逻辑

- [ ] 实现按小时/按天统计算法
- [ ] 实现工作时间分析算法
- [ ] 实现 996 指数计算
- [ ] 实现贡献者统计
- [ ] 实现多项目并发处理

**交付物**:
- 完整的统计算法
- 单元测试覆盖 > 80%

---

#### Phase 3: API 接口开发（2-3 天）

**目标**: 实现 RESTful API 接口

- [ ] 实现 `/api/dashboard/summary` 接口
- [ ] 实现 `/api/dashboard/contributors` 接口
- [ ] 实现参数验证
- [ ] 实现错误处理
- [ ] 配置 CORS

**交付物**:
- 完整的 API 接口
- API 文档
- 接口测试用例

---

#### Phase 4: 缓存与优化（2-3 天）

**目标**: 实现缓存机制和性能优化

- [ ] 集成 Redis 缓存
- [ ] 实现缓存策略
- [ ] 性能优化（并发、查询等）
- [ ] 添加请求限流
- [ ] 优化 Git 操作

**交付物**:
- 缓存服务
- 性能测试报告

---

#### Phase 5: 部署与监控（2-3 天）

**目标**: 完成部署配置和监控

- [ ] Docker 化
- [ ] 编写 docker-compose 配置
- [ ] 配置日志系统
- [ ] 实现健康检查
- [ ] 编写部署文档

**交付物**:
- Docker 镜像
- 部署文档
- 运维手册

---

#### Phase 6: 测试与上线（2-3 天）

**目标**: 完成测试并上线

- [ ] 单元测试
- [ ] 集成测试
- [ ] 性能测试
- [ ] 前后端联调
- [ ] 生产环境部署

**交付物**:
- 测试报告
- 上线检查清单
- 回滚方案

---

### 14.2 时间估算

| 阶段 | 工作日 | 说明 |
|------|--------|------|
| Phase 1 | 2-3 天 | 基础框架 |
| Phase 2 | 3-4 天 | 核心业务逻辑 |
| Phase 3 | 2-3 天 | API 接口 |
| Phase 4 | 2-3 天 | 缓存优化 |
| Phase 5 | 2-3 天 | 部署监控 |
| Phase 6 | 2-3 天 | 测试上线 |
| **总计** | **13-19 天** | **约 3-4 周** |

### 14.3 人员配置建议

- **1 名后端工程师**: 负责核心开发
- **0.5 名测试工程师**: 负责测试（可兼职）
- **0.5 名运维工程师**: 负责部署（可兼职）

---

## 15. 附录

### 15.1 完整示例代码

#### 主应用入口

```python
# app/main.py
from flask import Flask
from app.api.routes import api_bp
from app.middleware.cors import setup_cors
from app.utils.logger import setup_logger
import os

def create_app():
    """创建 Flask 应用"""
    
    app = Flask(__name__)
    
    # 加载配置
    app.config.from_object('app.config.Config')
    
    # 设置日志
    logger = setup_logger()
    
    # 设置 CORS
    setup_cors(app)
    
    # 注册 Blueprint
    app.register_blueprint(api_bp)
    
    # 错误处理
    @app.errorhandler(404)
    def not_found(error):
        return {"code": 404, "message": "接口不存在", "data": None}, 404
    
    @app.errorhandler(500)
    def internal_error(error):
        logger.error(f"服务器错误: {str(error)}")
        return {"code": 500, "message": "服务器内部错误", "data": None}, 500
    
    return app

# 创建应用实例
app = create_app()

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=8000, debug=True)
```

### 15.2 配置文件

```python
# app/config.py
import os
from dotenv import load_dotenv

load_dotenv()

class Config:
    """应用配置"""
    
    # Flask 配置
    SECRET_KEY = os.getenv('SECRET_KEY', 'dev-secret-key-change-in-production')
    DEBUG = os.getenv('DEBUG', 'False').lower() == 'true'
    
    # Redis 配置
    REDIS_HOST = os.getenv('REDIS_HOST', 'localhost')
    REDIS_PORT = int(os.getenv('REDIS_PORT', 6379))
    REDIS_DB = int(os.getenv('REDIS_DB', 0))
    
    # Git 配置
    GIT_WORKSPACE = os.getenv('GIT_WORKSPACE', './repos')
    GIT_MAX_DEPTH = int(os.getenv('GIT_MAX_DEPTH', 1000))
    
    # 缓存配置
    CACHE_TTL = int(os.getenv('CACHE_TTL', 300))  # 5 分钟
    
    # 性能配置
    MAX_WORKERS = int(os.getenv('MAX_WORKERS', 5))
    MAX_PROJECTS = int(os.getenv('MAX_PROJECTS', 50))
    
    # 日志配置
    LOG_LEVEL = os.getenv('LOG_LEVEL', 'INFO')
    LOG_DIR = os.getenv('LOG_DIR', './logs')
```

### 15.3 环境变量配置

```bash
# .env
DEBUG=False
SECRET_KEY=your-secret-key-here

# Redis
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_DB=0

# Git
GIT_WORKSPACE=./repos
GIT_MAX_DEPTH=1000

# 缓存
CACHE_TTL=300

# 性能
MAX_WORKERS=5
MAX_PROJECTS=50

# 日志
LOG_LEVEL=INFO
LOG_DIR=./logs
```

### 15.4 依赖清单

```
# requirements.txt
Flask==2.3.3
Flask-CORS==4.0.0
GitPython==3.1.37
redis==5.0.1
gunicorn==21.2.0
python-dotenv==1.0.0
psutil==5.9.6

# 开发依赖
pytest==7.4.3
pytest-cov==4.1.0
black==23.11.0
flake8==6.1.0
mypy==1.7.1
locust==2.18.0
```

### 15.5 快速启动脚本

```bash
#!/bin/bash
# start.sh

echo "================================"
echo "CODE996 Dashboard Backend"
echo "================================"

# 检查 Python 版本
python_version=$(python3 --version 2>&1 | awk '{print $2}')
echo "Python 版本: $python_version"

# 创建虚拟环境
if [ ! -d "venv" ]; then
    echo "创建虚拟环境..."
    python3 -m venv venv
fi

# 激活虚拟环境
echo "激活虚拟环境..."
source venv/bin/activate

# 安装依赖
echo "安装依赖..."
pip install -r requirements.txt

# 创建必要目录
mkdir -p repos logs

# 启动服务
echo "启动服务..."
echo "访问地址: http://localhost:8000"
echo "API 文档: http://localhost:8000/api/docs"
echo "================================"

python app/main.py
```

### 15.6 常见问题 FAQ

#### Q1: Git 仓库克隆失败？
**A**: 
- 检查网络连接
- 确认仓库 URL 正确
- 如果是私有仓库，配置 SSH 密钥或访问令牌

#### Q2: Redis 连接失败？
**A**:
- 检查 Redis 服务是否启动: `redis-cli ping`
- 检查配置的 host 和 port
- 系统会自动降级使用内存缓存

#### Q3: 性能慢？
**A**:
- 启用 Redis 缓存
- 增加并发 worker 数量
- 限制 Git log 深度
- 使用浅克隆（shallow clone）

#### Q4: 内存占用高？
**A**:
- 减少同时处理的项目数
- 限制 Git log 数量
- 及时清理旧的 Git 仓库

---

## 16. 总结

### 16.1 技术要点

1. **架构设计**: 分层架构，职责清晰
2. **性能优化**: 多级缓存、并发处理、索引优化
3. **安全性**: 输入验证、CORS 配置、访问控制
4. **可扩展性**: 模块化设计，易于扩展
5. **可维护性**: 完善的日志、监控、测试

### 16.2 最佳实践

- ✅ 使用 Git shallow clone 减少克隆时间
- ✅ 实现多级缓存提升响应速度
- ✅ 并发处理多个项目
- ✅ 完善的错误处理和日志记录
- ✅ Docker 化部署，环境一致
- ✅ 健康检查和监控

### 16.3 后续优化方向

1. **异步任务队列**: 使用 Celery 处理耗时任务
2. **WebSocket 支持**: 实时推送数据更新
3. **数据库持久化**: 存储历史统计数据
4. **权限管理**: 实现用户认证和授权
5. **CI/CD**: 自动化测试和部署
6. **国际化**: 支持多语言

---

## 17. 联系方式

**技术支持**:
- 邮箱: backend@code996.com
- 文档: [API接口文档.md](./API接口文档.md)
- 参考: [backend_example.py](./backend_example.py)

---

**文档版本**: v1.0.0  
**最后更新**: 2025-10-31  
**编写人**: 项目组  

---

**祝开发顺利！** 🚀

