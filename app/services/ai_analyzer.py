"""LLM AI 代码比例分析服务"""

from __future__ import annotations

import logging
import os
import re
from dataclasses import dataclass
from typing import Optional

import requests

from app.settings import (
    _optional_int,
    DEFAULT_AI_ANALYZER_ENDPOINT,
    DEFAULT_AI_ANALYZER_API_KEY,
    DEFAULT_AI_ANALYZER_MODEL,
)


logger = logging.getLogger('code996.services.ai_analyzer')


@dataclass
class AnalyzerConfig:
    endpoint: str
    api_key: str
    model: str
    max_tokens: int = 4096
    timeout: int = 60
    max_files: Optional[int] = None
    max_file_size: Optional[int] = None
    max_characters: Optional[int] = None


class AIAnalyzer:
    def __init__(self, config: Optional[AnalyzerConfig]) -> None:
        self.config = config
        self.enabled = config is not None and all([config.endpoint, config.api_key, config.model])

        if not self.enabled:
            logger.warning("AIAnalyzer 未启用，缺少必要配置")

    def analyze_content(self, file_path: str, content: str) -> Optional[float]:
        if not self.enabled or not content.strip():
            return None

        payload = {
            "model": self.config.model,
            "messages": [
                {
                    "role": "system",
                    "content": "【role】\nYou are a professional AI code detector capable of identifying the proportion of code generated by AI"
                },
                {
                    "role": "user",
                    "content": f"【TASK】\nDetect the proportion of AI-generated content in uploaded files (such as code, documents, etc.).\n【REQUIRE】\nReturn only the percentage.Now, please read the text and return the results.\n【TEXT】\n{content}",
                },
            ],
            "max_tokens": self.config.max_tokens,
        }

        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {self.config.api_key}",
        }

        try:
            response = requests.post(
                self.config.endpoint,
                json=payload,
                headers=headers,
                timeout=self.config.timeout,
            )
            response.raise_for_status()
            data = response.json()
        except requests.HTTPError as exc:
            response_text = exc.response.text if exc.response is not None else ""
            logger.error(
                "调用 AI 分析接口失败 (%s): %s | %s",
                file_path,
                exc,
                response_text[:2000],
            )
            return None
        except Exception as exc:
            logger.error("调用 AI 分析接口失败 (%s): %s", file_path, exc)
            return None

        percentage = self._extract_percentage(data)
        if percentage is None:
            logger.warning("AI 分析接口未返回有效百分比 (%s): %s", file_path, data)
        return percentage

    @staticmethod
    def _extract_percentage(response_json: dict) -> Optional[float]:
        try:
            choices = response_json.get("choices") or []
            if not choices:
                content = response_json.get("result") or response_json.get("output_text")
            else:
                content = choices[0].get("message", {}).get("content", "")
                if not content:
                    content = choices[0].get("text", "")
        except AttributeError:
            return None

        if not content:
            content = response_json.get("content") or ""

        match = re.search(r"(\d+(?:\.\d+)?)\s*%?", content)
        if not match:
            return None

        try:
            value = float(match.group(1))
        except ValueError:
            return None

        return max(0.0, min(100.0, value))
def build_analyzer_from_env() -> AIAnalyzer:
    def _env_or_default(key: str, default: str) -> str:
        value = os.getenv(key)
        if value is None or not value.strip():
            return default
        return value.strip()

    endpoint = _env_or_default('AI_ANALYZER_ENDPOINT', DEFAULT_AI_ANALYZER_ENDPOINT)
    api_key = _env_or_default('AI_ANALYZER_API_KEY', DEFAULT_AI_ANALYZER_API_KEY)
    model = _env_or_default('AI_ANALYZER_MODEL', DEFAULT_AI_ANALYZER_MODEL)

    max_tokens = int(os.getenv('AI_ANALYZER_MAX_TOKENS', 4096))
    timeout = int(os.getenv('AI_ANALYZER_TIMEOUT', 60))

    if not all([endpoint, api_key, model]):
        return AIAnalyzer(None)

    config = AnalyzerConfig(
        endpoint=endpoint,
        api_key=api_key,
        model=model,
        max_tokens=max_tokens,
        timeout=timeout,
        max_files=_optional_int(os.getenv('AI_ANALYZER_MAX_FILES')),
        max_file_size=_optional_int(os.getenv('AI_ANALYZER_MAX_FILE_SIZE')),
        max_characters=_optional_int(os.getenv('AI_ANALYZER_MAX_CHARACTERS')),
    )
    return AIAnalyzer(config)


